# Welcome to desafio-crawler ğŸ‘‹
[![Python Version](https://img.shields.io/badge/python-3.11-blue)](#)
[![Scrapy Version](https://img.shields.io/badge/Scrapy-2.11.0-blue)](#)
[![PostgreSQL Version](https://img.shields.io/badge/PostgreSQL-13-blue)](https://www.postgresql.org/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](#)

Este Ã© um projeto de raspagem de dados para o site IMDB, usando a biblioteca Scrapy.
Ele foi construÃ­do a partir das orientaÃ§Ãµes do desafio da  [beeMÃ´n](https://github.com/beemontech/desafio-crawler#beem%C3%B4n) ğŸ

O MVP + funcionalidades adicionais do desafio implementadas:

- Buscar dados de forma automatizada(script de linha de comando ou interface clicavel) âœ…
- Padronizar os retornos de forma estruturada (json/csv) âœ…
- Sistema de logs de para acompanhamento da execuÃ§Ã£o âœ…
- Ter um prova da consulta (Screenshot)  âœ…
- Armazenamento dos resultados em um banco relacional ou nÃ£o relacional âœ…
- Fazer um dataframe que possibilite visualizar os resultados via pandas âœ…
- Trazer resultados de forma dinamica sem fixar caminhos no xpath  âœ…
- Dockerizar a aplicaÃ§Ã£o âœ…
- Conseguir agendar uma execuÃ§Ã£o para um dia e horario. âœ…

### Tecnologias Utilizadas

- [Poetry](https://python-poetry.org/) (v1.1.12)
- [Python](https://www.python.org/) (v3.11.*)
- [Scrapy](https://scrapy.org/) (v2.11.0)
- [scrapy-playwright](https://github.com/scrapy-plugins/scrapy-playwright) (v0.0.33)
- [schendule](https://schedule.readthedocs.io/en/stable/#) (1.2.1)
- [pandas](https://pandas.pydata.org/) (^2.1.3)
- [sqlalchemy](https://www.sqlalchemy.org/) (^2.0.23)

## Executando o projeto:
  >  **Nota:**  Certifique-se de ter o Docker e o Docker Compose instalados.Veja a [documentaÃ§Ã£o](https://docs.docker.com/get-docker/), caso ainda nÃ£o os tenha instalado.

1. Clone o repositÃ³rio:

    ```bash
    git clone https://github.com/AnaCandida/desafio-crawler.git
    ```

2. Navegue atÃ© a pasta do projeto e execute:

    ```bash
    docker-compose up -d --build  OU docker compose up -d --build
    ```


## ExecuÃ§Ã£o e Agendamento do IMDB Spider

### Agendamento(default):
Por padrÃ£o, o container executarÃ¡ automaticamente o script para agendamento do spider.
Ele permitirÃ¡ que vocÃª escolha o dia da semana e a hora para o agendamento.

>  **Nota:** Para manter o agendamento ativo, Ã© crucial manter o script em execuÃ§Ã£o. Caso o script seja encerrado, o agendamento serÃ¡ perdido.
>Isso inclui reinicializaÃ§Ãµes do container. A implementaÃ§Ã£o dessa persistÃªncia pode ser considerada como uma funcionalidade futura.


### Se preferir rodar o spider uma Ãºnica vez, utilize o seguinte comando:

```
docker-compose run scrapy_service run_once

```



## Detalhes sobre as implementaÃ§Ãµes ğŸ“š:

Este projeto proporcionou uma imersÃ£o mais aprofundada nos conceitos de web scraping, oferecendo um entendimento abrangente da biblioteca Scrapy, bem como sua integraÃ§Ã£o eficaz com a biblioteca scrapy_playwright.

ImplementaÃ§Ãµes Realizadas:

- Middleware customizado para rotaÃ§Ã£o de user-agent e ajudar a evitar bloqueios
- Pipeline customizada para integraÃ§Ã£o com banco de dados Postgres
- Salvamento em lote no banco de dados para melhorar performance
- Metodo para evitar o carregamento de recursos desnecessÃ¡rios, como imagens e solicitaÃ§Ãµes POST, otimizando assim a performance
- Agendamento interativo do usuario via terminal




## Author

ğŸ‘©ğŸ»â€ğŸ’» **Ana CÃ¢ndida Pereira de Quadros**

* Github: [@AnaCandida](https://github.com/AnaCandida)
* LinkedIn: [@https:\/\/www.linkedin.com\/in\/anacandidaquadros\/](https://linkedin.com/in/https:\/\/www.linkedin.com\/in\/anacandidaquadros\/)

## LicenÃ§a

Este projeto estÃ¡ licenciado sob a [LicenÃ§a MIT](LICENSE).