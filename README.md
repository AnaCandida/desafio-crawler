# Welcome to desafio-crawler üëã
[![Python Version](https://img.shields.io/badge/python-3.11-blue)](#)
[![Scrapy Version](https://img.shields.io/badge/Scrapy-2.11.0-blue)](#)
[![PostgreSQL Version](https://img.shields.io/badge/PostgreSQL-13-blue)](https://www.postgresql.org/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](#)

Este √© um projeto de raspagem de dados para o site IMDB, usando a biblioteca Scrapy.
Ele foi constru√≠do a partir das orienta√ß√µes do desafio da  [beeM√¥n](https://github.com/beemontech/desafio-crawler#beem%C3%B4n) üêù

O MVP + funcionalidades adicionais do desafio implementadas:

- Buscar dados de forma automatizada(script de linha de comando ou interface clicavel) ‚úÖ
- Padronizar os retornos de forma estruturada (json/csv) ‚úÖ
- Sistema de logs de para acompanhamento da execu√ß√£o ‚úÖ
- Ter um prova da consulta (Screenshot)  ‚úÖ
- Armazenamento dos resultados em um banco relacional ou n√£o relacional ‚úÖ
- Fazer um dataframe que possibilite visualizar os resultados via pandas ‚úÖ
- Trazer resultados de forma dinamica sem fixar caminhos no xpath  ‚úÖ
- Dockerizar a aplica√ß√£o ‚úÖ
- Conseguir agendar uma execu√ß√£o para um dia e horario. ‚úÖ

### Tecnologias Utilizadas

- [Poetry](https://python-poetry.org/) (v1.1.12)
- [Python](https://www.python.org/) (v3.11.*)
- [Scrapy](https://scrapy.org/) (v2.11.0)
- [scrapy-playwright](https://github.com/scrapy-plugins/scrapy-playwright) (v0.0.33)
- [schendule](https://schedule.readthedocs.io/en/stable/#) (1.2.1)
- [pandas](https://pandas.pydata.org/) (^2.1.3)
- [sqlalchemy](https://www.sqlalchemy.org/) (^2.0.23)

## Executando o projeto:
  >  **Nota:**  Certifique-se de ter o Docker e o Docker Compose instalados.Veja a [documenta√ß√£o](https://docs.docker.com/get-docker/), caso ainda n√£o os tenha instalado.

1. Clone o reposit√≥rio:

    ```bash
    git clone https://github.com/AnaCandida/desafio-crawler.git
    ```

2. Navegue at√© a pasta do projeto e execute:

    ```bash
    docker-compose up -d --build  OU docker compose up -d --build
    ```


## Execu√ß√£o e Agendamento do IMDB Spider

### Agendamento:
O script `run_schedule.py` permitir√° que voc√™ escolha o dia da semana e a hora para o agendamento do spider.

1. Voc√™ pode acessar o shell do container:
    ```
    docker exec -it /desafio-crawler-scrapy_service-1 /bin/sh
    ```

2. Rodar o seguinte comando:

  ```
  python run_schedule.py
  ```

>  **Nota:** Para manter o agendamento ativo, √© crucial manter o script em execu√ß√£o. Caso o script seja encerrado, o agendamento ser√° perdido.
>Isso inclui reinicializa√ß√µes do container.


###  Execu√ß√£o √∫nica:

Se preferir rodar o spider uma √∫nica vez, utilize o seguinte comando dentro do sheel do container:

  ```
  python run_schedule.py run_once

  ```



## Detalhes sobre as implementa√ß√µes üìö:

Este projeto proporcionou uma imers√£o mais aprofundada nos conceitos de web scraping, oferecendo um entendimento abrangente da biblioteca Scrapy, bem como sua integra√ß√£o eficaz com a biblioteca scrapy_playwright.

Implementa√ß√µes Realizadas:

- Middleware customizado para rota√ß√£o de user-agent e ajudar a evitar bloqueios
- Pipeline customizada para integra√ß√£o com banco de dados Postgres.Isso facilita a manuten√ß√£o e a reusabilidade do c√≥digo, separando as preocupa√ß√µes de extra√ß√£o e armazenamento.
- Class Item para defintir a estrutura dos dados extra√≠dos e manter a consist√™ncia.
- ItemLoader para criar e limpar os dados extra√≠dos. Uso de MapCompose, Takefirt e  Compose.
- Salvamento em lote no banco de dados para reduzir a sobrecarga de opera√ß√µes de banco de dados, melhorando a performance geral.
- Metodo para evitar o carregamento de recursos desnecess√°rios, como imagens e solicita√ß√µes POST, otimizando assim a performance
- Agendamento interativo do usuario via terminal




## Author

üë©üèª‚Äçüíª **Ana C√¢ndida Pereira de Quadros**

* Github: [@AnaCandida](https://github.com/AnaCandida)
* LinkedIn: [@https:\/\/www.linkedin.com\/in\/anacandidaquadros\/](https://linkedin.com/in/https:\/\/www.linkedin.com\/in\/anacandidaquadros\/)

## Licen√ßa

Este projeto est√° licenciado sob a [Licen√ßa MIT](LICENSE).